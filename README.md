# Webcrawler

## Запуск

```shell
docker-compose up
```

## Описание

Проект состоит из 3 сервисов:

- crawler-service: REST API с 1-м эндпоинтом, который отвечает за принятие запросов с урлами. Используя модуль parser, 
достает из html-страницы ее тайтл и передает данные клиенты, а также кладет их в кафку для дальнейшей обработки.
Для оптимизации запросов приложение сохраняет обработанные html-страницы в базу данных (mongo) + используется redis для 
кэширования.
- document-service: Kafka consumer сервис, который сохраняет обработанные документы из кафки в базу. Из дополнений,
также этот сервис должен заниматься дедупликацией html-страниц.
- refresher: Сервис периодических тасок. Проверяет сохраненные html-страницы в базе на изменение их тайтлов.
